/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
syntax = "proto2";

package fluss;
option java_package = "org.apache.fluss.rpc.messages";
option optimize_for = LITE_RUNTIME;

/**
* NOTICE: To ensure a smooth upgrade to Proto3 syntax while maintaining backward compatibility in
* the future, please adhere to the following limitations:
* 1. DO NOT USE "default" keyword, proto3 removes the support of "default"
* 2. DO NOT USE "enum" type
 */

// the message indicates a failed request of a server failure.
message ErrorResponse {
  required int32 error_code = 1;
  optional string error_message = 2;
}

message ApiVersionsRequest {
  required string client_software_name = 1;
  required string client_software_version = 2;
}

message ApiVersionsResponse {
  repeated PbApiVersion api_versions = 1;
}

// get schema request and response
message GetTableSchemaRequest {
  required PbTablePath table_path = 1;
  optional int32 schema_id = 2;
}

message GetTableSchemaResponse {
  required int32 schema_id = 1;
  required bytes schema_json = 2;
}

// create database request and response
message CreateDatabaseRequest {
  required string database_name = 1;
  required bool ignore_if_exists = 2;
  optional bytes database_json = 3;
}

message CreateDatabaseResponse {
}

// get table request and response
message GetDatabaseInfoRequest {
  required string database_name = 1;
}

message GetDatabaseInfoResponse {
  required bytes database_json = 3;
  required int64 created_time = 4;
  required int64 modified_time = 5;
}

// drop database request and response
message DropDatabaseRequest {
  required string database_name = 1;
  required bool ignore_if_not_exists = 2;
  required bool cascade = 3;
}
message DropDatabaseResponse {
}

// database exists request and response
message DatabaseExistsRequest {
  required string database_name = 1;
}
message DatabaseExistsResponse {
  required bool exists = 1;
}

// list databases request and response
message ListDatabasesRequest {
}
message ListDatabasesResponse {
  repeated string database_name = 1;
}

// create table request and response
message CreateTableRequest {
  required PbTablePath table_path = 1;
  required bytes table_json = 2;
  required bool ignore_if_exists = 3;
}

message CreateTableResponse {
}

// alter table request and response
message AlterTableRequest {
  required PbTablePath table_path = 1;
  required bool ignore_if_not_exists = 2;
  repeated PbAlterConfig config_changes = 3;
}


message AlterTableResponse {
}



// get table request and response
message GetTableInfoRequest {
  required PbTablePath table_path = 1;
}

message GetTableInfoResponse {
  required int64 table_id = 1;
  required int32 schema_id = 2;
  required bytes table_json = 3;
  required int64 created_time = 4;
  required int64 modified_time = 5;
}

// list tables request and response
message ListTablesRequest {
  required string database_name = 1;
}

message ListTablesResponse {
  repeated string table_name = 1;
}

// drop table request and response
message DropTableRequest {
  required PbTablePath table_path = 1;
  required bool ignore_if_not_exists = 2;
}

message DropTableResponse {
}

// table exists request and response
message TableExistsRequest {
  required PbTablePath table_path = 1;
}

message TableExistsResponse {
  required bool exists = 1;
}

// metadata request and response, request send from client to each server.
message MetadataRequest {
  repeated PbTablePath table_path = 1;
  repeated PbPhysicalTablePath partitions_path = 2;

  // note: currently, we assume the partition ids must belong to the table_paths in the
  // metadata request
  // todo: we won't need the assumption after we introduce metadata cache in server
  repeated int64 partitions_id = 3 [packed = true];
}

message MetadataResponse {
  optional PbServerNode coordinator_server = 1;
  repeated PbServerNode tablet_servers = 2;
  repeated PbTableMetadata table_metadata = 3;
  repeated PbPartitionMetadata partition_metadata = 4;
}

// update metadata request and response, only send between server.
message UpdateMetadataRequest {
  optional PbServerNode coordinator_server = 1;
  repeated PbServerNode tablet_servers = 2;
  repeated PbTableMetadata table_metadata = 3;
  repeated PbPartitionMetadata partition_metadata = 4;
  optional int32 coordinator_epoch = 5;
}

message UpdateMetadataResponse {
}

// produce log request and response
message ProduceLogRequest {
  required int32 acks = 1;
  required int64 table_id = 2;
  required int32 timeout_ms = 3;
  repeated PbProduceLogReqForBucket buckets_req = 4;
}

message ProduceLogResponse {
  repeated PbProduceLogRespForBucket buckets_resp = 1;
}

// fetch log request and response
message FetchLogRequest {
  required int32 follower_server_id = 1;  // value -1 indicate the request from client.
  required int32 max_bytes = 2;
  repeated PbFetchLogReqForTable tables_req = 3;
  optional int32 max_wait_ms = 4;
  optional int32 min_bytes = 5;
}

message FetchLogResponse {
  repeated PbFetchLogRespForTable tables_resp = 1;
}

// put kv request and response
message PutKvRequest {
  required int32 acks = 1;
  required int64 table_id = 2;
  required int32 timeout_ms = 3;
  // the indexes for the columns to write,
  // if empty, means write all columns
  repeated int32 target_columns = 4 [packed = true];
  repeated PbPutKvReqForBucket buckets_req = 5;
}

message PutKvResponse {
  repeated PbPutKvRespForBucket buckets_resp = 1;
}

// lookup request and response
message LookupRequest {
  required int64 table_id = 1;
  repeated PbLookupReqForBucket buckets_req = 2;
}

message LookupResponse {
  repeated PbLookupRespForBucket buckets_resp = 1;
}

// Prefix Lookup request and response
message PrefixLookupRequest {
  required int64 table_id = 1;
  repeated PbPrefixLookupReqForBucket buckets_req = 2;
}

message PrefixLookupResponse {
  repeated PbPrefixLookupRespForBucket buckets_resp = 1;
}


// limit scan request and response
message LimitScanRequest {
  required int64 table_id = 2;
  optional int64 partition_id = 3;
  required int32 bucket_id = 4;
  required int32 limit = 5;
}

message LimitScanResponse{
  optional int32 error_code = 1;
  optional string error_message = 2;
  // flag to indicate the table type
  optional bool is_log_table = 3;
  // LogRecordBatch if is_log_table is true, otherwise KvRecordBatch
  optional bytes records = 4;
}


// notify bucket leader and isr request
message NotifyLeaderAndIsrRequest {
  required int32 coordinator_epoch = 1;
  repeated PbNotifyLeaderAndIsrReqForBucket notify_buckets_leader_req = 2;
}

// response for notify bucket leader and isr request
message NotifyLeaderAndIsrResponse {
  repeated PbNotifyLeaderAndIsrRespForBucket notify_buckets_leader_resp = 1;
}

// stop bucket replica request
message StopReplicaRequest {
  required int32 coordinator_epoch = 1;
  repeated PbStopReplicaReqForBucket stop_replicas_req = 2;
}

// response for stop bucket replica request
message StopReplicaResponse {
  repeated PbStopReplicaRespForBucket stop_replicas_resp = 1;
}

// adjust isr request and response
message AdjustIsrRequest {
  required int32 serverId = 1;
  repeated PbAdjustIsrReqForTable tables_req = 2;
}

message AdjustIsrResponse {
  repeated PbAdjustIsrRespForTable tables_resp = 1;
}

// list offsets request and response
message ListOffsetsRequest {
  required int32 follower_server_id = 1;  // value -1 indicate the request from client.
  required int32 offset_type = 2; // value can be 0,1,2 (see ListOffsetsParam for more details)
  required int64 table_id = 3;
  optional int64 partition_id = 4;
  repeated int32 bucket_id = 5 [packed = true]; // it is recommended to use packed for repeated numerics to get more efficient encoding
  optional int64 startTimestamp = 6;
}
message ListOffsetsResponse {
  repeated PbListOffsetsRespForBucket buckets_resp = 1;
}

// commit kv snapshot request and response
message CommitKvSnapshotRequest {
  required bytes completed_snapshot = 1;
  required int32 coordinator_epoch = 2;
  required int32 bucket_leader_epoch = 3;
}

message CommitKvSnapshotResponse {
}

// notify the log offset about kv snapshot
message NotifyKvSnapshotOffsetRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int32 coordinator_epoch = 4;
  required int64 min_retain_offset = 5;
}

message NotifyKvSnapshotOffsetResponse {
}

message GetLatestKvSnapshotsRequest {
  required PbTablePath table_path = 1;
  optional string partition_name = 2;
}

message GetLatestKvSnapshotsResponse {
  required int64 table_id = 1;
  // null if it is a non-partitioned table, otherwise, it must be not null
  optional int64 partition_id = 2;
  repeated PbKvSnapshot latest_snapshots = 3;
}

message GetKvSnapshotMetadataRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int64 snapshot_id = 4;
}

message GetKvSnapshotMetadataResponse {
  required int64 log_offset = 1;
  repeated PbRemotePathAndLocalFile snapshot_files = 2;
}

message GetLatestLakeSnapshotRequest {
  required PbTablePath table_path = 1;
}

message GetLatestLakeSnapshotResponse {
  required int64 table_id = 1;
  required int64 snapshotId = 2;
  repeated PbLakeSnapshotForBucket bucket_snapshots = 3;
}

message GetFileSystemSecurityTokenRequest {
}

message GetFileSystemSecurityTokenResponse {
  required string schema = 1;
  required bytes token = 2;
  optional int64 expiration_time = 3;
  repeated PbKeyValue addition_info = 4;
}

// init writer request and response
message InitWriterRequest {
  repeated PbTablePath table_path = 1;
}

message InitWriterResponse {
  required int64 writer_id = 1;
}

message ListPartitionInfosRequest {
  required PbTablePath table_path = 1;
  optional PbPartitionSpec partial_partition_spec = 2;
}

message ListPartitionInfosResponse {
  repeated PbPartitionInfo partitions_info = 1;
}

// create partition request and response
message CreatePartitionRequest {
  required PbTablePath table_path = 1;
  required PbPartitionSpec partition_spec = 2;
  required bool ignore_if_not_exists = 3;
}

message CreatePartitionResponse {}

// drop partition request and response
message DropPartitionRequest {
  required PbTablePath table_path = 1;
  required PbPartitionSpec partition_spec = 2;
  required bool ignore_if_not_exists = 3;
}

message DropPartitionResponse {}

// commit remote log manifest request and response
message CommitRemoteLogManifestRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required string remote_log_manifest_path = 4;
  required int64 remote_log_start_offset = 5;
  required int64 remote_log_end_offset = 6;
  required int32 coordinator_epoch = 7;
  required int32 bucket_leader_epoch = 8;
}

message CommitRemoteLogManifestResponse {
  required bool commitSuccess = 1;
}

// notify remote log offsets request and response
message NotifyRemoteLogOffsetsRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int32 coordinator_epoch = 4;
  required int64 remote_start_offset = 5;
  required int64 remote_end_offset = 6;
}

message NotifyRemoteLogOffsetsResponse {
}

message CommitLakeTableSnapshotRequest {
  repeated PbLakeTableSnapshotInfo tables_req = 1;
}

message PbLakeTableSnapshotInfo {
  optional int64 table_id = 1;
  required int64 snapshot_id = 2;
  repeated PbLakeTableOffsetForBucket buckets_req = 3;
}

message PbLakeTableOffsetForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int64 log_start_offset = 3;
  optional int64 log_end_offset = 4;
  optional string partition_name = 5;
  optional int64 max_timestamp = 6;
}

message CommitLakeTableSnapshotResponse {
  repeated PbCommitLakeTableSnapshotRespForTable table_resp = 1;
}

message PbCommitLakeTableSnapshotRespForTable {
  required int64 table_id = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message NotifyLakeTableOffsetRequest {
  required int32 coordinator_epoch = 1;
  repeated PbNotifyLakeTableOffsetReqForBucket notify_buckets_req = 2;
}

message PbNotifyLakeTableOffsetReqForBucket {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int64 snapshot_id = 4;
  optional int64 log_start_offset = 5;
  optional int64 log_end_offset = 6;
  optional int64 max_timestamp = 7;
}

message NotifyLakeTableOffsetResponse {
}

message AuthenticateRequest {
  required string protocol = 1;
  required bytes token = 2;
}

message AuthenticateResponse {
  optional bytes challenge = 1;
}

// acl related requests and responses
message ListAclsRequest{
  required PbAclFilter acl_filter = 1;
}

message ListAclsResponse{
  repeated PbAclInfo acl = 1;
}

message CreateAclsRequest{
  repeated PbAclInfo acl = 1;
}

message CreateAclsResponse{
  repeated PbCreateAclRespInfo aclRes = 1;
}

message DropAclsRequest{
  repeated PbAclFilter acl_filter = 1;
}

message DropAclsResponse{
  repeated PbDropAclsFilterResult filter_results = 1;
}

message LakeTieringHeartbeatRequest {
  repeated PbHeartbeatReqForTable tiering_tables = 1;
  repeated PbHeartbeatReqForTable finished_tables = 2;
  repeated PbHeartbeatReqForTable failed_tables = 3;
  // whether to request a table
  optional bool request_table = 4;
}

message LakeTieringHeartbeatResponse {
  // coordinator epoch
  required int32 coordinator_epoch = 1;
  // the returned table to tier, empty when no table is needed by the lake tiering service
  optional PbLakeTieringTableInfo tiering_table = 2;
  repeated PbHeartbeatRespForTable tiering_table_resp = 3;
  repeated PbHeartbeatRespForTable finished_table_resp = 4;
  repeated PbHeartbeatRespForTable failed_table_resp = 5;
}

message ControlledShutdownRequest {
  required int32 tablet_server_id = 1;
  required int32 tablet_server_epoch = 2;
}

message ControlledShutdownResponse {
  repeated PbTableBucket remaining_leader_buckets = 1;
}

message DescribeClusterConfigsRequest{
}


message DescribeClusterConfigsResponse{
  repeated PbDescribeConfig configs = 1;
}

message AlterClusterConfigsRequest{
  repeated PbAlterConfig alter_configs = 1;
}

message AlterClusterConfigsResponse{
}



// --------------- Inner classes ----------------
message PbApiVersion {
  required int32 api_key = 1;
  required int32 min_version = 2;
  required int32 max_version = 3;
}

message PbTablePath {
  required string database_name = 1;
  required string table_name = 2;
}

message PbPhysicalTablePath {
  required string database_name = 1;
  required string table_name = 2;
  optional string partition_name = 3;
}

// For MetadataResponse, host and port are still used for all versions.
// For UpdateMetadataRequest,
//   * versions <= 0.6: host and port are used.
//   * versions >= 0.7: listeners is used to replace host and port.
// For MetadataResponse and UpdateMetadataRequest: Fluss versions >= 0.7: we add rack for each tabletServer
message PbServerNode {
  required int32 node_id = 1;
  required string host = 2;
  required int32 port = 3;
  optional string listeners = 4;
  optional string rack = 5;
}

message PbTableMetadata {
  required PbTablePath table_path = 1;
  required int64 table_id = 2;
  required int32 schema_id = 3;
  required bytes table_json = 4;
  repeated PbBucketMetadata bucket_metadata = 5;
  required int64 created_time = 6;
  required int64 modified_time = 7;

  // TODO add a new filed 'deleted_table' to indicate this table is deleted in UpdateMetadataRequest.
  // trace by: https://github.com/apache/fluss/issues/981
}

message PbPartitionMetadata {
  required int64 table_id = 1;
  // the partition name and id for the partition
  required string partition_name = 2;
  required int64 partition_id = 3;
  repeated PbBucketMetadata bucket_metadata = 4;
}

message PbBucketMetadata {
  required int32 bucket_id = 1;
  // optional as some time the leader may not elected yet
  optional int32 leader_id = 2;
  repeated int32 replica_id = 3 [packed = true];
  // TODO: Add isr here.
  optional int32 leader_epoch = 4;
}

message PbProduceLogReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  required bytes records = 3;
}

message PbProduceLogRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  optional int64 base_offset = 5;
}

message PbFetchLogReqForTable {
  required int64 table_id = 1;
  required bool projection_pushdown_enabled = 2;
  repeated int32 projected_fields = 3 [packed = true];
  repeated PbFetchLogReqForBucket buckets_req = 4;
}

message PbFetchLogReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  // TODO leader epoch
  required int64 fetch_offset = 3;
  required int32 max_fetch_bytes = 4;
}

message PbFetchLogRespForTable {
  required int64 table_id = 1;
  repeated PbFetchLogRespForBucket buckets_resp = 2;
}
message PbFetchLogRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  optional int64 high_watermark = 5;
  optional int64 log_start_offset = 6; // TODO now we don't introduce log start offset, but remain it in protobuf
  optional PbRemoteLogFetchInfo remote_log_fetch_info = 7;
  optional bytes records = 8;
}

message PbPutKvReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  required bytes records = 3;
}

message PbPutKvRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
}

message PbLookupReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  repeated bytes keys = 3;
}

message PbLookupRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  repeated PbValue values = 5;
}

message PbValue {
  // optional, if empty, means no value
  optional bytes values = 1;
}

message PbValueList {
  repeated bytes values = 1;
}

message PbPrefixLookupReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  repeated bytes keys = 3;
}

message PbPrefixLookupRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  repeated PbValueList value_lists = 5;
}

message PbTableBucket {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
}

message PbAdjustIsrReqForTable {
  required int64 table_id = 1;
  repeated PbAdjustIsrReqForBucket buckets_req = 2;
}


message PbAdjustIsrReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  required int32 leader_epoch = 3;
  repeated int32 new_isr = 4 [packed = true];
  required int32 coordinator_epoch = 5;
  required int32 bucket_epoch = 6;
}

message PbAdjustIsrRespForTable {
  required int64 table_id = 1;
  repeated PbAdjustIsrRespForBucket buckets_resp = 2;
}

message PbAdjustIsrRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  optional int32 leader_id = 5;
  optional int32 leader_epoch = 6;
  repeated int32 isr = 7 [packed = true];
  optional int32 bucket_epoch = 8;
  optional int32 coordinator_epoch = 9;
}

message PbListOffsetsRespForBucket {
  required int32 bucket_id = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
  optional int64 offset = 4;
}

message PbNotifyLeaderAndIsrReqForBucket {
  // we need table path for tablet server to create data dir for the bucket,
  // although tablet server don't need it after it has created data dir.
  // For simplicity, we always pass table path.
  required PbPhysicalTablePath physical_table_path = 1;
  required PbTableBucket table_bucket = 2;
  required int32 leader = 3;
  required int32 leader_epoch = 4;
  repeated int32 replicas = 5 [packed = true];
  repeated int32 isr = 6 [packed = true];
  required int32 bucket_epoch = 7;
}

message PbNotifyLeaderAndIsrRespForBucket {
  required PbTableBucket table_bucket = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message PbStopReplicaReqForBucket {
  required PbTableBucket table_bucket = 1;
  required int32 leader_epoch = 2;
  required bool delete = 3;
}

message PbStopReplicaRespForBucket {
  required PbTableBucket table_bucket = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message PbKvSnapshot {
  required int32 bucket_id = 1;
  // null if there is no snapshot for this bucket
  optional int64 snapshot_id = 2;
  // null if there is no snapshot for this bucket, then read from EARLIEST
  optional int64 log_offset = 3;
}

message PbLakeSnapshotForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int64 log_offset = 3;
  optional string partition_name = 4;
}

message PbRemotePathAndLocalFile {
  required string remote_path = 1;
  required string local_file_name = 2;
}

message PbKeyValue {
  required string key = 1;
  required string value = 2;
}

message PbRemoteLogFetchInfo {
  required string remote_log_tablet_dir = 1;
  optional string partition_name = 2;
  repeated PbRemoteLogSegment remote_log_segments = 3;
  optional int32 first_start_pos = 4;
}

message PbRemoteLogSegment {
  required string remote_log_segment_id = 1;
  required int64 remote_log_start_offset = 2;
  required int64 remote_log_end_offset = 3;
  required int32 segment_size_in_bytes = 4;
  optional int64 max_timestamp = 5;
}

message PbPartitionInfo {
  required int64 partition_id = 1;
  required PbPartitionSpec partition_spec = 2;
}

message PbPartitionSpec {
  repeated PbKeyValue partition_key_values = 1;
}

message PbCreateAclRespInfo {
  required PbAclInfo acl = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message PbAclInfo {
  required string resource_name = 1;
  required int32 resource_type = 2;
  required string principal_name = 3;
  required string principal_type = 4;
  required string host = 5;
  required int32 operation_type = 6;
  required int32 permission_type = 7;
}

message PbAclFilter {
  optional string resource_name = 1;
  required int32 resource_type = 2;
  optional string principal_name = 3;
  optional string principal_type = 4;
  optional string host = 5;
  required int32 operation_type = 6;
  required int32 permission_type = 7;
}

message PbDropAclsFilterResult {
  repeated PbDropAclsMatchingAcl matching_acls = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;

}

message PbDropAclsMatchingAcl {
  required PbAclInfo acl = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message PbLakeTieringTableInfo {
  required int64 table_id = 1;
  required PbTablePath table_path = 2;
  required int64 tiering_epoch = 3;
}

message PbHeartbeatReqForTable {
  required int64 table_id = 1;
  // the coordinator epoch when the table is assigned to be tiering service
  required int32 coordinator_epoch = 2;
  // the tiering epoch when the table is assigned to be tiering service
  required int64 tiering_epoch = 3;
}

message PbHeartbeatRespForTable {
  required int64 table_id = 1;
  optional ErrorResponse error = 2;
}

message PbAlterConfig {
  required string config_key = 1;
  optional string config_value = 2;
  required int32 op_type = 3; // SET=0, DELETE=1, APPEND=2, SUBTRACT=3
}

message PbDescribeConfig{
  required string config_key = 1;
  optional string config_value = 2;
  required string config_source = 3;
}

// A scan request. Initially, it should specify a scan. Later on, you
// can use the scanner id returned to fetch result batches with a different
// scan request.
//
// The scanner will remain open if there are more results, and it's not
// asked to be closed explicitly.
//
// Clients may choose to retry scan requests that fail to complete (due to, for
// example, a timeout or network error).
//
// You can fetch the results and ask the scanner to be closed to save
// a trip if you are not interested in remaining results.
message PBScanReq {
  // If continuing an existing scan, then you must set scanner_id.
  // Otherwise, you must set 'new_scan_request'.
  optional bytes scanner_id = 1;
  optional PBNewScanReq new_scan_request = 2;

  // The sequence ID of this call. The sequence ID should start at 0
  // with the request for a new scanner, and after each successful request,
  // the client should increment it by 1. When retrying a request, the client
  // should _not_ increment this value. If the server detects that the client
  // missed a chunk of rows from the middle of a scan, it will respond with an
  // error.
  optional uint32 call_seq_id = 3;

  // The maximum number of bytes to send in the response.
  optional uint32 batch_size_bytes = 4;

  // If set, the server will close the scanner after responding to
  // this request, regardless of whether all rows have been delivered.
  optional bool close_scanner = 5;

  // Query id is used to trace the whole process of reading tablets.
  optional bytes query_id = 6;
}

message PBNewScanReq {
  // The tablet to scan.
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;

  // The maximum number of rows to scan with the new scanner.
  //
  // The scanner will automatically stop yielding results and close itself
  // after reaching this number of result rows.
  optional uint64 limit = 4;
}

message PBScanResp {
  // The error, if an error occurred with this request.
  optional int32 error_code = 1;
  optional string error_message = 2;

  // When a scanner is created, returns the scanner ID which may be used
  // to pull new rows from the scanner.
  optional bytes scanner_id = 3;

  // Set to true to indicate that there may be further results to be fetched
  // from this scanner. If the scanner has no more results, then the scanner
  // ID will become invalid and cannot continue to be used.
  //
  // Note that if a scan returns no results, then the initial response from
  // the first RPC may return false in this flag, in which case there will
  // be no scanner ID assigned.
  optional bool has_more_results = 4;

  // The block of returned rows.
  //
  // NOTE: the schema-related fields will not be present in this row block.
  // The schema will match the schema requested by the client when it created
  // the scanner.
  optional bytes records = 5;

  // Returns the corresponding log offset at the time the scanner is created
  optional int64 log_offset = 6;
}

// A scanner keep-alive request.
// Updates the scanner access time, increasing its time-to-live.
message PBScannerKeepAliveReq {
  required bytes scanner_id = 1;
}

message PBScannerKeepAliveResp {
  // The error, if an error occurred with this request.
  optional int32 error_code = 1;
  optional string error_message = 2;
}